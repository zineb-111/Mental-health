
# ZINEB EL MEJDOUBI
**Num√©ro d'√©tudiant** : 24010156
**Classe** : CAC2


# Compte rendu

üìä Analyse de l'√âquilibre entre Usage des R√©seaux Sociaux et Sant√© Mentale 

**Date :** 3 d√©cembre 2025
# Task
## Rapport Final : Analyse des Facteurs Influencant l'Indice de Bonheur

## 1. Introduction

Ce rapport d√©taille une analyse compl√®te des facteurs influen√ßant l'indice de bonheur, bas√©e sur le jeu de donn√©es "Mental_Health_Dataset.csv". L'objectif principal √©tait de mod√©liser l'indice de bonheur √† la fois comme une variable continue (r√©gression) et comme une variable cat√©gorielle (classification), afin d'identifier les pr√©dicteurs cl√©s et de comparer l'efficacit√© de diff√©rentes approches d'apprentissage automatique.

## 2. M√©thodologie

### 2.1. Nettoyage et Pr√©paration des Donn√©es

*   **Chargement des Donn√©es**: Le jeu de donn√©es initial a √©t√© charg√© depuis KaggleHub.
*   **Gestion des Valeurs Manquantes et Doublons**: Aucune valeur manquante ni doublon n'a √©t√© identifi√©e dans le jeu de donn√©es initial ou apr√®s pr√©traitement, assurant une bonne int√©grit√© des donn√©es d√®s le d√©part.
*   **Suppression de Caract√©ristiques Inutiles**: La colonne `User_ID`, identifiant unique sans valeur pr√©dictive, a √©t√© supprim√©e.
*   **Encodage des Variables Cat√©gorielles**: Les variables cat√©gorielles `Gender` et `Social_Media_Platform` ont √©t√© transform√©es en variables num√©riques via *One-Hot Encoding*.
*   **Normalisation des Donn√©es Num√©riques**: Les caract√©ristiques num√©riques (`Age`, `Daily_Screen_Time(hrs)`, `Sleep_Quality(1-10)`, `Stress_Level(1-10)`, `Days_Without_Social_Media`, `Exercise_Frequency(week)`) ont √©t√© normalis√©es √† l'aide de `StandardScaler` pour assurer que toutes les caract√©ristiques contribuent √©galement √† la mod√©lisation.

### 2.2. Exploration des Donn√©es (EDA) et Ing√©nierie de Caract√©ristiques

*   **Analyse de Corr√©lation**: Une matrice de corr√©lation a √©t√© calcul√©e et visualis√©e, r√©v√©lant des relations cl√©s avec l'indice de bonheur :
    *   **Qualit√© du Sommeil** (`Sleep_Quality(1-10)`): Forte corr√©lation positive (0.68).
    *   **Niveau de Stress** (`Stress_Level(1-10)`): Forte corr√©lation n√©gative (-0.74).
    *   **Temps d'√âcran Quotidien** (`Daily_Screen_Time(hrs)`): Forte corr√©lation n√©gative (-0.71).
*   **Ing√©nierie de Caract√©ristiques**: Une nouvelle caract√©ristique, `Well_Being_Score`, a √©t√© cr√©√©e en combinant les trois variables les plus corr√©l√©es (`Sleep_Quality(1-10)` - `Stress_Level(1-10)` - `Daily_Screen_Time(hrs)`). Cette variable composite visait √† capturer un indice global de bien-√™tre.

### 2.3. Strat√©gie de Mod√©lisation

*   **Division des Donn√©es**: Le jeu de donn√©es a √©t√© divis√© en ensembles d'entra√Ænement (80%) et de test (20%) pour √©valuer la g√©n√©ralisabilit√© des mod√®les.
*   **Validation Crois√©e**: Une strat√©gie de validation crois√©e `KFold` (5 splits, shuffle=True) a √©t√© utilis√©e pour l'√©valuation robuste des mod√®les de r√©gression et l'optimisation des hyperparam√®tres.
*   **Algorithmes Test√©s**:
    *   **R√©gression (cible continue)**: R√©gression Lin√©aire Simple, R√©gression Lin√©aire Multiple, R√©gression Polynomiale (degr√© 2), R√©gression Ridge, R√©gression Lasso, Arbre de D√©cision, For√™t Al√©atoire (non optimis√©e et optimis√©e).
    *   **Classification (cible cat√©gorielle)**: R√©gression Logistique Multiclasse (apr√®s discr√©tisation de la variable cible `Happiness_Index(1-10)` en 'faible' (0-6), 'moyen' (7-8) et '√©lev√©' (9-10)).

## 3. R√©sultats & Discussion

### 3.1. Mod√®les de R√©gression (Variable Cible Continue)

Le tableau ci-dessous r√©capitule les performances des diff√©rents mod√®les de r√©gression sur l'ensemble de test :

| Mod√®le                            | R-carr√© | MSE  | MAE  |
| :-------------------------------- | :------ | :--- | :--- |
| R√©gression Lin√©aire Simple        | 0.53 | 1.12 | 0.88 |
| R√©gression Lin√©aire Multiple      | 0.61 | 0.93 | 0.80 |
| R√©gression Polynomiale (Degr√© 2)  | 0.50 | 1.18 | 0.92 |
| R√©gression Ridge                  | 0.61 | 0.93 | 0.80 |
| R√©gression Lasso                  | **0.63** | **0.89** | 0.79 |
| Arbre de D√©cision                 | 0.37 | 1.49 | 0.89 |
| For√™t Al√©atoire (non optimis√©e)   | 0.60 | 0.94 | 0.77 |
| For√™t Al√©atoire (optimis√©e)       | 0.62 | 0.91 | **0.76** |

*   **Analyse des Performances**:
    *   La **R√©gression Lasso** a montr√© la meilleure performance en termes de R-carr√© (0.63), mais la **For√™t Al√©atoire (optimis√©e)** a obtenu un MAE l√©g√®rement inf√©rieur (0.76 vs 0.79 pour Lasso), indiquant des pr√©dictions en moyenne plus proches des valeurs r√©elles.
    *   Les mod√®les lin√©aires r√©gularis√©s (Ridge, Lasso) ont surperform√© la r√©gression lin√©aire multiple non r√©gularis√©e, montrant l'efficacit√© de la r√©gularisation pour la g√©n√©ralisation.
    *   La r√©gression polynomiale de degr√© 2 n'a pas apport√© d'am√©lioration significative, sugg√©rant que les relations complexes ne sont pas simplement quadratiques ou qu'un degr√© sup√©rieur serait n√©cessaire avec un risque de surapprentissage accru.
    *   L'**Arbre de D√©cision** seul a √©t√© le moins performant, soulignant la puissance des m√©thodes d'ensemble comme la For√™t Al√©atoire.
    *   L'optimisation des hyperparam√®tres de la For√™t Al√©atoire a l√©g√®rement am√©lior√© sa performance par rapport √† la version non optimis√©e.

### 3.2. Mod√®le de Classification (Variable Cible Cat√©gorielle)

La variable `Happiness_Index(1-10)` a √©t√© discr√©tis√©e en 'faible' (0-6), 'moyen' (7-8), et '√©lev√©' (9-10). Un mod√®le de R√©gression Logistique Multiclasse a √©t√© appliqu√©.

*   **Performances Globales**: Une pr√©cision globale (accuracy) de **73%** a √©t√© atteinte sur l'ensemble de test.
*   **Performance par Cat√©gorie**:
    *   **Cat√©gorie '√©lev√©'**: Tr√®s bien pr√©dite (Pr√©cision: 0.80, Rappel: 0.92, F1-score: 0.85).
    *   **Cat√©gorie 'moyen'**: Performances mod√©r√©es (Pr√©cision: 0.65, Rappel: 0.59, F1-score: 0.62).
    *   **Cat√©gorie 'faible'**: La plus difficile √† pr√©dire, avec un faible Rappel (0.33), souvent confondue avec la cat√©gorie 'moyen' (8 des 12 cas 'faible' r√©els ont √©t√© class√©s comme 'moyen').
*   **Matrice de Confusion**: La matrice de confusion a clairement montr√© le d√©s√©quilibre dans la pr√©diction, avec la difficult√© √† identifier correctement la classe minoritaire 'faible'.

## 4. Conclusion

### R√©sum√© des Facteurs Influencant l'Indice de Bonheur

L'analyse exhaustive, tant en r√©gression qu'en classification, converge vers un ensemble de facteurs cl√©s qui influencent de mani√®re significative l'indice de bonheur :

*   **Niveau de Stress** (`Stress_Level(1-10)`): Sans surprise, c'est le facteur le plus fortement et n√©gativement li√© au bonheur. Un stress √©lev√© est un puissant pr√©dicteur d'un faible indice de bonheur.
*   **Qualit√© du Sommeil** (`Sleep_Quality(1-10)`): Cruciale pour le bien-√™tre, une meilleure qualit√© de sommeil est fortement associ√©e √† un indice de bonheur plus √©lev√©.
*   **Temps d'√âcran Quotidien** (`Daily_Screen_Time(hrs)`): Un temps d'√©cran plus √©lev√© est associ√© √† une diminution de l'indice de bonheur, soulignant l'importance de la mod√©ration.
*   **Autres Facteurs**: L'√¢ge, la fr√©quence de l'exercice et les pr√©f√©rences pour les plateformes de m√©dias sociaux contribuent √©galement, bien que leur impact soit moins direct et plus nuanc√©, souvent captur√© par les mod√®les plus complexes comme la For√™t Al√©atoire.

La sup√©riorit√© des mod√®les non lin√©aires et d'ensemble (For√™t Al√©atoire) en r√©gression sugg√®re que les relations entre ces facteurs et le bonheur ne sont pas toujours simples, impliquant des interactions et des seuils que les mod√®les lin√©aires peinent √† capturer. Pour la classification, le mod√®le logistique est efficace pour les cat√©gories '√©lev√©', mais la pr√©diction des cat√©gories 'faible' reste un d√©fi en raison du d√©s√©quilibre des classes.

### Limites des Mod√®les D√©velopp√©s

*   **Interpr√©tabilit√© vs Performance**: Les mod√®les les plus performants (For√™t Al√©atoire, Lasso) peuvent √™tre moins directement interpr√©tables que la r√©gression lin√©aire simple, particuli√®rement la For√™t Al√©atoire qui est une "bo√Æte noire".
*   **D√©s√©quilibre de Classe en Classification**: La difficult√© du mod√®le de r√©gression logistique √† pr√©dire la cat√©gorie 'faible' bonheur est une limitation due au nombre restreint d'exemples pour cette classe.
*   **G√©n√©ralisabilit√©**: Les mod√®les sont entra√Æn√©s sur un jeu de donn√©es sp√©cifique ; leur performance pourrait varier sur d'autres populations ou contextes.

### Propositions Concr√®tes de Pistes d'Am√©lioration Futures

*   **R√©√©quilibrage des Classes**: Pour la classification, impl√©menter des techniques telles que SMOTE ou l'ajustement des poids des classes pour am√©liorer la d√©tection des cat√©gories minoritaires.
*   **Optimisation Avanc√©e des Hyperparam√®tres**: Explorer `RandomizedSearchCV` ou des optimisations bay√©siennes pour une recherche plus efficace et potentiellement de meilleurs hyperparam√®tres, surtout pour les mod√®les comme la For√™t Al√©atoire ou d'autres mod√®les d'ensemble.
*   **Mod√®les Avanc√©s**: Tester des algorithmes plus sophistiqu√©s tels que XGBoost, LightGBM, ou des r√©seaux de neurones pour capturer des relations encore plus complexes.
*   **Ing√©nierie de Caract√©ristiques**: Continuer √† explorer la cr√©ation de caract√©ristiques d√©riv√©es, en particulier des termes d'interaction, qui pourraient mieux repr√©senter les influences combin√©es de plusieurs facteurs.
*   **Collecte de Donn√©es Suppl√©mentaires**: Pour adresser le d√©s√©quilibre des classes et am√©liorer la robustesse des mod√®les, la collecte de donn√©es suppl√©mentaires, en particulier pour les cat√©gories sous-repr√©sent√©es, serait b√©n√©fique.

Ce rapport fournit une base solide pour comprendre les dynamiques de l'indice de bonheur et ouvre la voie √† des recherches et des d√©veloppements futurs plus approfondis.
